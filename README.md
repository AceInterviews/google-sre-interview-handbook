# âš¡ The "Google SRE" Interview Handbook (2026+ Edition)

> **"The definitive open-source playbook for the modern Google Site Reliability Engineer (SRE). Moving beyond LeetCode to NALS, Linux Internals, and Reliability Architecture.An open-source map of how Google evaluates modern Site Reliability Engineers (SREs) â€” not a list of things to memorize."**

This repository documents the **mental models, evaluation rubrics, and failure patterns** behind modern Google SRE interviews.

It is not a question bank.
It is not a LeetCode guide.
It is not sufficient by itself.

It explains **how you are judged** â€” not whether you can execute under pressure.


[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](http://makeapullrequest.com)


## ğŸš¨ Why Most Strong Candidates Still Fail

Most Google SRE interview prep material is frozen in 2018:

* generic algorithms
* abstract system design
* surface-level DevOps checklists

The modern Google SRE loop evaluates something else entirely:

**Operational Maturity under incomplete information.**

Specifically:

1. **NALS (Non-Abstract Large System Design)**
   Can you *diagnose and stabilize* a system you didnâ€™t build â€” before redesigning it?

2. **Linux Internals & Kernel Reasoning**
   Can you debug resource contention without guessing or dashboard hopping?

3. **Reliability Architecture**
   Can you reason in error budgets, trade-offs, and blast radius â€” not features?

Many senior engineers fail not because they lack knowledge, but because they **sequence actions incorrectly under pressure**.

This repository exists to make that rubric visible.

---

## ğŸ“š Whatâ€™s Inside (Foundational Only)

These documents capture **how interviewers think**, not how to â€œwinâ€ interviews.

*   **[The NALS Diagnostic Flowchart for Google SRE Interviews](nals-playbook.md)** - How to stabilize and debug large-scale outages. How strong candidates stabilize first, investigate second, redesign last.
*   **[The Linux Internals Cheat Sheet for Google SRE Interviews](linux-internals.md)** - The 20 commands that solve 80% of incidents. The signal hierarchy behind the commands â€” not command memorization.
*   **[Coding Patterns for Google SRE Interviews](coding-patterns.md)** - Python/Go patterns for concurrency, retries, and rate limiting. How automation, streaming, and safety are evaluated in coding rounds.
*   **[Behavioral: The Google SRE-STAR(M) Method](behavioral-guide.md)** - How to answer "Tell me about a time..." with metrics. How Google scores impact, not storytelling.
*   **[Negotiation Pocket Card for Google SRE Interviews](negotiation-tips.md)** - Scripts to maximize your offer. How offers are evaluated internally, not how blogs describe negotiation.
*   **[Interviewer Scorecards: How Candidates Are Evaluated](interviewer-scorecards.md)** â€“ The internal dimensions interviewers use to assess trust, judgment, and seniority. This repository exposes evaluation lenses, not solutions â€” because performance under pressure cannot be memorized.
*   **[Counter-Patterns: What Passing Candidates Do Differently](counter-patterns.md)** â€“ The behavioral habits that separate hires from rejections.
*   **[Failure Patterns in Google SRE Interviews](failure-patterns.md)** â€“ Why strong candidates fail despite knowing the right answers.

> **Counter-Patterns**
> This document captures how successful Google SRE candidates sequence decisions, narrate intent, and manage uncertainty differently. It focuses on behavior under pressure, not technical knowledge.


> **Failure Patterns:**
> This document catalogs recurring ways senior engineers fail Google SRE interviews â€” not due to lack of knowledge, but due to mis-sequencing decisions under pressure. It is designed to make failure modes visible, not solvable.

---

## ğŸ§  The Google SRE Mastery Pyramid (What Seniority Actually Means)

Passing senior/staff loops requires moving beyond *tool usage* into *systems reasoning*.

| Layer         | Whatâ€™s Evaluated                    | What Most Candidates Miss     |
| ------------- | ----------------------------------- | ----------------------------- |
| Culture       | Blamelessness, RCAs, error budgets  | Treating outages as bugs      |
| Incident Eng  | Mitigate â†’ Localize â†’ Fix â†’ Prevent | Root-cause obsession          |
| Observability | Kernel signals > dashboards         | Metrics as lagging indicators |
| Linux         | Resource contention reasoning       | Command guessing              |
| Kernel        | Scheduling, memory, networking      | â€œCPU is fineâ€ fallacy         |

This pyramid is descriptive â€” not aspirational.

---

## ğŸ“˜ Interview-Grade Linux Command Playbook (Excerpt)

> This is not a Linux cheatsheet.
> This is how Google evaluates *judgment* through command choice.

Most candidates know `tail`, `ps`, `lsof`.

Very few can explain **why that command, at that moment, under uncertainty**.


That difference is scored and decides interviews.


## ğŸ¯ Why This Module Exists

In Google SRE interviews:

* You are **not evaluated on command memorization**
* You *are* evaluated on:

  * prioritization
  * signal selection
  * reasoning under uncertainty
  * calm narration of thought process

Interviewers listen closely to:

> *â€œWhy did you choose that command?â€*

This playbook teaches **command â†’ intent â†’ signal** mapping.


## ğŸ§  The Mental Model Interviewers Expect

Before touching the keyboard, strong SREs silently ask:

1. Is this a **live system or historical issue**?
2. Am I looking for **symptoms or root cause**?
3. Is the problem **CPU, memory, I/O, network, or application-level**?
4. What is the **lowest-cost, highest-signal command** to start with?

This module trains that reflex.



## ğŸ”¥ Section 1 â€” Log Inspection (The First 5 Minutes Matter)

### `tail -f` â€” Live Signal, Not Noise

**When to use**

* Incident is ongoing
* You want to correlate behavior with time

**Interview narration**

> â€œIâ€™ll start with `tail -f` to observe real-time behavior before making assumptions.â€

**Example**

```bash
tail -f /var/log/nginx/error.log
```

**Signal interviewers look for**

* You didnâ€™t start grepping blindly
* You value *temporal correlation*



### `tail -n` â€” Context Before Panic

**When to use**

* Incident already occurred
* You want *recent history*, not the full log

```bash
tail -n 200 /var/log/app.log
```

**What this shows**

* You understand **blast radius**
* You donâ€™t overload yourself with data



### `grep` + `tail` â€” Precision Over Volume

Bad candidates:

```bash
grep error /var/log/app.log
```

Strong candidates:

```bash
tail -n 5000 /var/log/app.log | grep -i timeout
```

**Why this matters**

* Shows scoped thinking
* Shows intent to reduce false positives



## âš™ï¸ Section 2 â€” Process & Resource Awareness

### `ps aux` â€” Snapshot Thinking

**When to use**

* Need a fast view of resource-heavy processes

```bash
ps aux --sort=-%cpu | head
```

**Interview signal**

* You understand *static snapshots vs dynamic metrics*



### `top` vs `htop` â€” Conscious Tool Choice

**Good explanation**

> â€œIâ€™ll use `top` first for a quick system-wide view before drilling deeper.â€

Interviewers care **why**, not **which**.



## ğŸ§µ Section 3 â€” File Descriptors & Hidden Killers

### `lsof` â€” The Silent Outage Detector

**Use cases**

* Port binding failures
* File descriptor exhaustion
* Stuck deleted files consuming disk

```bash
lsof -i :8080
```

**Narration**

> â€œThis helps confirm whether the service is actually listening or blocked by another process.â€



## ğŸ’¾ Section 4 â€” Disk & I/O (Where Seniors Stand Out)

### `df -h` vs `du -sh`

Strong candidates **never confuse these**.

```bash
df -h
du -sh /var/*
```

**Key insight**

* `df` = filesystem view
* `du` = directory view

Interviewers *love* this distinction.



## ğŸ§  Section 5 â€” Memory & Kernel Signals

### `free -m`

```bash
free -m
```

**Strong explanation**

> â€œIâ€™m checking memory pressure and reclaim behavior before assuming a leak.â€

Bonus points if candidate mentions:

* page cache
* swap behavior



## ğŸŒ Section 6 â€” Network Sanity Checks

### `netstat` / `ss`

```bash
ss -lntp
```

**Use when**

* Service unreachable
* Connection exhaustion suspected

**Narration**

> â€œThis confirms whether the service is bound and accepting connections.â€



## ğŸ” Section 7 â€” Putting It Together (Interview Scenario)

**Question**

> â€œThe site is slow. CPU is normal. What do you do?â€

**Strong answer flow**

1. `tail -n` logs for recent anomalies
2. `ss` to check connection backlog
3. `iostat` / disk wait (if available)
4. Only then form hypotheses

This shows:
âœ” restraint
âœ” prioritization
âœ” system thinking



## ğŸš« Common Interview Red Flags

Interviewers immediately notice when candidates:

* start grepping entire logs
* run commands without explaining intent
* jump tools without hypothesis
* over-optimize too early

This module trains you *out* of those habits.


## â­ Why This Section Improves Coding & Scripting Rounds

Even in **coding interviews**, Google evaluates:

* how you reason about input size
* streaming vs batch thinking
* observability mindset

Candidates who think like SREs:

* choose iterators
* avoid loading everything into memory
* explain tradeoffs clearly

This command mindset **directly transfers** to code.


## ğŸ¯ Final Takeaway

Google doesnâ€™t hire people who know Linux commands.

Google hires people who:

* know **which signal matters first**
* stay calm under ambiguity
* explain their thinking clearly
* choose tools intentionally

This playbook teaches exactly that.

---

## ğŸš« Where This Repository Intentionally Stops

This repository does **not** teach:

* executing these frameworks under interruption
* recovering after choosing the wrong first step
* handling mid-interview constraint reversals
* narrating trade-offs while being challenged

Those are **execution skills**, not reading skills.

This distinction matters.

Many candidates understand everything here â€” and still fail.

---

## ğŸš€ If You Want to Train Execution (Not Just Understanding)

I built a **simulation-based preparation system** specifically to train:

* sequencing under pressure
* partial-information debugging
* interviewer-style interruptions
* recovery after wrong decisions

It exists because reading frameworks does not build reflexes.

ğŸ‘‰ **The Complete Google SRE Career Launchpad**
[https://aceinterviews.gumroad.com/l/Google_SRE_Interviews_Your_Secret_Bundle_to_Conquer](https://aceinterviews.gumroad.com/l/Google_SRE_Interviews_Your_Secret_Bundle_to_Conquer)

Included:

* 20+ failure-driven production simulations
* coding exercises scored like Google scores them
* kernel & networking deep dives with interviewer prompts
* negotiation scripts that reflect real committee logic

Use it or donâ€™t â€” but understand the difference.

---

## ğŸš€ Want the Complete System?

This repository covers the **foundational frameworks**.

If you want the **complete end-to-end preparation system**â€”including practice workbooks, mock simulations, and deep-dive scenariosâ€”check out the full bundle:

ğŸ‘‰ **[The Complete Google SRE Career Launchpad (Gumroad)](https://aceinterviews.gumroad.com/l/Google_SRE_Interviews_Your_Secret_Bundle_to_Conquer)**

**What's included in the full bundle:**
*   ğŸ“˜ **20+ Production Scenarios:** Deep dives into Kernel Panics, BGP Leaks, and connection storms.
*   ğŸ **Coding Workbooks (Python & Go):** 70+ practice problems focusing on concurrency, automation, and safety.
*   ğŸ’¼ **The Negotiation Playbook:** Word-for-word scripts to increase your offer.
*   ğŸ“… **The 30-Day Prep Schedule:** A day-by-day roadmap to interview readiness.

---

## ğŸ¤ Contributing
Contributions are welcome! Please open an issue or PR if you have additional commands, patterns, or interview insights to share.

## ğŸ“„ License
MIT License. Free to use and share.
